# Case-study оптимизации

## Актуальная проблема
Дана программа на `ruby`, которая обработывает файл с данными. 

Программа успешно работает с небольшими файлами в 657 байт (18 строк), но при попытке передать на обработку файл 128 
мегабайт (3250940 строк) не удаётся дождаться выполнения программы. При этом нет гарантий, что обработка файла когда-нибудь будет 
завершена.

Я решил исправить эту проблему, оптимизировав эту программу.

### Мантры оптимизации:
1) **"Оптимизировать только когда метрика не укладывается в бюджет"**

В данном случае действительно метрика не укладывается в бюджет.
Метрикой в данном задании выступает время обработки файла.
Требуется обрабатывать файл размером 128 мегабайт хотябы меньше, чем за 30 секунд.
Будем ориентироваться на этот бюджет.
В настоящий момент время обратоки составляет более 15 минут, и нет уверенности, что обратока будет когда-нибудь 
выполнена.

Итог:

Для обрабатываемого файла в 128 мегабайт  следующие значения:
* Метрика - время обработки файла в 128 мегабайт
* Бюджет - максимум 30 секунд на обработку файла в 128 мегабайт

2) **"Оптимизировать только главную точку роста"**

Нельзя оптимизировать в слепую всё подряд, нужно точно определить проблемные места.
В противном случае есть риск демотивации.

Итог:
* Нужно найти главную точку роста.

### Общий фреймврок оптимизации
- Защищаем поведение системы от внесения ошибок тестом (есть вероятность сломать какой-то участок кода при оптимизации, поэтому стоит защищать оптимизуемые участки кода);
- Сортируем проблемы по степени значимости (выбираем главную проблему и концентрируемся на ней);
- Фиксируем/формируем метрику
- Фиксируем/формируем бюджет на метрику
- Защищаем метрику от дальнейшей деградации тестом (пишем тест на производительность);
- Профилируем, вникаем в детали системы чтобы найти главную точку роста
- Выстраивам Feedback-Loop (мы нашли главную точку роста и пытаемся улучшить метрику системы)
    - Loop: профилируем -> вносим изменения -> запускаем тесты -> измеряем (benchmark) -> commit/revert
- Обновляем тест для защиты достигнутого прогресса
- Формируем case-study, считаем $$

### Анализ асимптотики
Беглый анализ асимптотики. 
Программа характеризуется объёмом входных даннных. 
Сейчас практически невозможно узнать время выполнения обработки файла `data_large.txt`. 
Так как "программа характеризется объёмом входых данных" создам 4-е файла объёмом 10_000 строк (1x), 20_000 (2x), 
30_000 (3x) и 40_000 строк (4x) и посмотреть отличия времени обработки для этих 
файлов.

За исходный файл возьму data_large.txt и воспользуюсь следующей командой:
```shell
head -n N data_large.txt > dataN.txt
```
Таким образом можно примерно увидеть алгоритмическую сложность.

1) Создадим файл с бэнчмарком для обработки файла `asymptotic_benchmark.rb`, где и будем запускать указаные выше файлы;
2) Сначала, попробовал запустить 4 раза обработку одного и того же файлов, в результате первый раз файл обрабатывался 
за 1x времени, 2-ой раз - за 1.1x, а остальные 2-е обработки за 1.25x каждый. 
```
10000 lines:
Finish in 2.54 (1)
Finish in 2.77 (2)
Finish in 3.14 (3)
Finish in 3.13 (4)
```
Отключение сборщика мусора (`GC.disable`) исправило эту проблему и каждый запуск обработки файла стал отрабатывать с одинаковым временем
```
10000 lines:
Finish in 3.22 (1)
Finish in 3.3 (2)
Finish in 3.31 (3)
Finish in 3.26 (4)
```
3) Теперь мы уверены, что не произойдёт замедление из-за сборщика мусора, а значит по очереди замерим обработку 4 файлов: на 10000 строк, 20000 строк, 30000 строк и 40000 строк. Рузультат получился следующий
```   
Finish in 3.28 (10000 lines)
Finish in 20.15 (20000 lines)
Finish in 50.87 (30000 lines)
Finish in 93.74 (40000 lines)
```
Время увеличивается как 1x, 6.14x, 15.5x, 28.58x при размерности файлов в строках 10к, 20к, 30к и 40к соответственно. 
Исхоя из этих данных можно предположить, что на данный момент сложнность алгоритма составляет как мимнимум O(n^2).
4) Для точности также можно применить `benchmark-ips`. Для этого создадим файл `asymptotic_benchmark_ips.rb`. 
Для ускорения его работы уменьшу все файлы до 1к, 2к, 3к и 4к строк соответственно. Получим следующий результат:
```
Warming up --------------------------------------
          1000 lines     2.000  i/100ms
          2000 lines     1.000  i/100ms
          3000 lines     1.000  i/100ms
          4000 lines     1.000  i/100ms
Calculating -------------------------------------
          1000 lines     24.882  (± 2.3%) i/s -    124.000  in   5.037254s
          2000 lines      8.932  (± 1.8%) i/s -     45.000  in   5.061260s
          3000 lines      4.621  (± 1.6%) i/s -     24.000  in   5.203014s
          4000 lines      2.756  (± 2.6%) i/s -     14.000  in   5.095583s
                   with 95.0% confidence
```
Как видно результат схож с первой. Похоже на O(n^2)

## Формирование метрики
Для того, чтобы понимать, оказывают ли мои изменения положительный эффект на быстродействие программы я придумал 
использовать такую метрику: **время обработки файла в 128 мегабайт**

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. 
Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации. 

Перенесту тест на фреймворк RSpec для удобства. Так как далее согласно фреймворку 
оптимизации потребуется защитить метрику от деградации, удобнее это сделать с помощью `rspec-benchmark`. 
Также на первом этапе я разделил исходный файл `task-1.rb` на `lib/handling/user.rb` (содержит класс User) и 
`lib/handling/user_repository.rb` (содержит функциональность обработки файла и записи отчёта в json) сами функции 
**изменению не подверглись**. 
Тестирование обработки файла перенесено в `spec/lib/handling/user_repository_spec.rb`.

Добавлен Performance-тест на обработу файла размером 20_000 строк не более чем за 26 секунды (до начала оптимизации кода).

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, 
который позволил мне получать обратную связь по эффективности сделанных изменений за 20.08 секунд (20_000 строк)

Вот как я построил `feedback_loop`: 
 - запуск тестов
 - запуск профилировщиков
 - анализ времени выполнения 
 - анализ главой точки роста
 - внесение изменений в код
 - прогон тестов
 - при улучшении скорости работы корректировка Performance-теста (защита от деградации)
 
## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *инструментами, которыми вы воспользовались*
- rbspy, он показал что главной точкой роста является block в функции work, он захватывает более 95% всего времени CPU 
(однако функция имеет несколько блоков) её стоит декомпозировать на несколько функций.

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?